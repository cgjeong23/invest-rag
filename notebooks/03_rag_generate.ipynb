{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd14e3a7",
   "metadata": {},
   "source": [
    "# 03. RAG Generation (Orchestration Only)\n",
    "\n",
    "This notebook orchestrates:\n",
    "\n",
    "- Retrieval (vector / LLM rerank)\n",
    "- Context construction\n",
    "- LLM generation with citation validation + optional two-pass retry\n",
    "- Optional run logging\n",
    "\n",
    "All core logic lives in `src/`. This notebook only wires components together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "825f548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\CG\\Desktop\\invest-rag\n",
      "Artifacts: c:\\Users\\CG\\Desktop\\invest-rag\\indexes\\faiss\n",
      "Ready: vector_search_fn / rerank_search_fn\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Project root convention: run notebooks from repo root (invest-rag/)\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "assert (PROJECT_ROOT / \"src\").exists(), f\"Run from project root. cwd={PROJECT_ROOT}\"\n",
    "\n",
    "#artifacts\n",
    "INDEX_DIR  = PROJECT_ROOT / \"indexes\" / \"faiss\"\n",
    "INDEX_PATH = INDEX_DIR / \"index.bin\"\n",
    "META_PATH  = INDEX_DIR / \"meta.jsonl\"\n",
    "\n",
    "assert INDEX_PATH.exists(), f\"Missing index: {INDEX_PATH}\"\n",
    "assert META_PATH.exists(),  f\"Missing meta:  {META_PATH}\"\n",
    "\n",
    "#retrieval modules\n",
    "from src.llm.embedding import embed_query\n",
    "from src.retrieval.vector_store import VectorStore\n",
    "from src.eval.search_wrappers import make_vectorstore_search_fn, make_llm_rerank_search_fn\n",
    "\n",
    "vs = VectorStore.load(index_path=INDEX_PATH, meta_path=META_PATH)\n",
    "\n",
    "vector_search_fn = make_vectorstore_search_fn(vs, embed_query=embed_query, normalize=True)\n",
    "rerank_search_fn = make_llm_rerank_search_fn(vector_search_fn, k_vec=10)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"Artifacts:\", INDEX_DIR)\n",
    "print(\"Ready: vector_search_fn / rerank_search_fn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890286a6",
   "metadata": {},
   "source": [
    "## Context + Generation\n",
    "\n",
    "We reuse the existing modules:\n",
    "\n",
    "- `src/llm/context.py`: `build_context(results) -> str`\n",
    "- `src/llm/generate.py`: `rag_generate_with_retry(query, context, retrieved) -> (answer, ok)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74585f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm.context import build_context\n",
    "from src.llm.generate import rag_generate_with_retry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6bf5e9",
   "metadata": {},
   "source": [
    "## Run Logging (Optional)\n",
    "\n",
    "Logs each run as a JSONL row under `logs/run_logs.jsonl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309729de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "RUNLOG_PATH = PROJECT_ROOT / \"logs\" / \"run_logs.jsonl\"\n",
    "\n",
    "def log_run(payload: dict, path: Path = RUNLOG_PATH) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    row = {\"ts\": datetime.datetime.now().isoformat(timespec=\"seconds\"), **payload}\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd8984",
   "metadata": {},
   "source": [
    "## Orchestration\n",
    "\n",
    "- Choose retrieval mode: vector vs rerank\n",
    "- Retrieve top-k results\n",
    "- Build context (from `src/llm/context.py`)\n",
    "- Generate grounded answer with citations (from `src/llm/generate.py`)\n",
    "- Return answer + sources list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5a10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_RERANK = False\n",
    "K = 5\n",
    "\n",
    "def retrieve(query: str, k: int = K, use_rerank: bool = USE_RERANK):\n",
    "    fn = rerank_search_fn if use_rerank else vector_search_fn\n",
    "    return fn(query, k)\n",
    "\n",
    "def format_sources(results: list[dict], max_items: int = 8) -> list[str]:\n",
    "    \"\"\"Minimal helper (not retrieval logic): pretty-print sources.\"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for r in results:\n",
    "        doc_id = r.get(\"doc_id\")\n",
    "        if not doc_id:\n",
    "            continue\n",
    "        title = (r.get(\"title\") or \"\").strip()\n",
    "        date  = (r.get(\"date\") or \"\").strip()\n",
    "        src   = (r.get(\"source\") or \"\").strip()\n",
    "\n",
    "        s = f\"[{doc_id}] {title}\".strip()\n",
    "        tail = \", \".join([x for x in [date, src] if x])\n",
    "        if tail:\n",
    "            s += f\" ({tail})\"\n",
    "\n",
    "        if s not in seen:\n",
    "            seen.add(s)\n",
    "            out.append(s)\n",
    "        if len(out) >= max_items:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def run_query(query: str, *, use_rerank: bool = USE_RERANK, k: int = K) -> dict:\n",
    "    retrieved = retrieve(query, k=k, use_rerank=use_rerank)\n",
    "\n",
    "    # ‚úÖ context module (no duplicated logic)\n",
    "    context = build_context(retrieved)\n",
    "\n",
    "    if not context.strip():\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"answer\": \"Not enough context. Retrieved empty context.\",\n",
    "            \"ok\": False,\n",
    "            \"sources\": [],\n",
    "            \"retrieved\": retrieved,\n",
    "        }\n",
    "\n",
    "    # ‚úÖ generation module (includes citation validation + retry)\n",
    "    answer, ok = rag_generate_with_retry(query=query, context=context, retrieved=retrieved)\n",
    "\n",
    "    # optional logging\n",
    "    log_run({\n",
    "        \"query\": query,\n",
    "        \"k_ctx\": k,\n",
    "        \"use_rerank\": use_rerank,\n",
    "        \"ok\": ok,\n",
    "        \"retrieved\": [\n",
    "            {\n",
    "                \"rank\": r.get(\"rank\"),\n",
    "                \"doc_id\": r.get(\"doc_id\"),\n",
    "                \"chunk_id\": r.get(\"chunk_id\"),\n",
    "                \"score\": r.get(\"score\"),\n",
    "                \"title\": r.get(\"title\"),\n",
    "            }\n",
    "            for r in retrieved\n",
    "        ],\n",
    "        \"answer\": answer,\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"ok\": ok,\n",
    "        \"sources\": format_sources(retrieved),\n",
    "        \"retrieved\": retrieved,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bce2c",
   "metadata": {},
   "source": [
    "## Grounding Strategy (Two-Pass)\n",
    "\n",
    "`rag_generate_with_retry()` implements a two-pass strategy:\n",
    "\n",
    "1. First pass: generate answer with `[doc_id]` citations.\n",
    "2. Validate citations against retrieved doc_ids.\n",
    "3. If invalid ‚Üí retry while restricting allowed doc_ids.\n",
    "\n",
    "This reduces hallucinated citations while keeping latency low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e9205",
   "metadata": {},
   "source": [
    "## Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68838778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The foundational programming model that runs on all NVIDIA GPUs is the CUDA programming model. NVIDIA describes it as central to its full-stack offering because it serves as the base for a large body of software, including hundreds of domain-specific software libraries, software development kits (SDKs), and Application Programming Interfaces (APIs). This comprehensive software stack accelerates performance and simplifies the deployment of NVIDIA accelerated computing for computationally intensive workloads such as AI model training and inference, data analytics, scientific computing, and 3D graphics. The CUDA model, along with the CUDA-X collection of acceleration libraries and domain-specific application frameworks, enables NVIDIA to provide a unified architecture that supports diverse computing requirements across various industries, making it a key element of their full-stack computing platform [nvidia_2024_item_1_business].\n",
      "\n",
      "Valid citations: True\n",
      "\n",
      "Sources:\n",
      "[nvidia_2024_item_1_business] (sec_10k_html)\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the foundational programming model that runs on all NVIDIA GPUs, and why does NVIDIA describe it as central to its full-stack offering?\"\n",
    "\n",
    "out = run_query(q, use_rerank=False, k=5)\n",
    "\n",
    "print(out[\"answer\"])\n",
    "print(\"\\nValid citations:\", out[\"ok\"])\n",
    "print(\"\\nSources:\")\n",
    "print(\"\\n\".join(out[\"sources\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3888a14",
   "metadata": {},
   "source": [
    "When queried about an out-of-distribution company (Tesla), the system correctly abstains from hallucinating and reports insufficient evidence in the retrieved context, while still providing citation transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5ad4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have enough information about the risk factors of Tesla in the provided context. The documents only include risk factors related to NVIDIA and Apple.\n",
      "\n",
      "Valid citations: True\n",
      "\n",
      "Sources:\n",
      "[nvidia_2024_item_7_mda] (sec_10k_html)\n",
      "[apple_2024_item_1a_risk_factors] (sec_10k_html)\n",
      "[nvidia_2024_item_1_business] (sec_10k_html)\n"
     ]
    }
   ],
   "source": [
    "unrelated_q = \"Explain Risk Factors of the company Tesla\"\n",
    "\n",
    "out = run_query(unrelated_q, use_rerank=False, k=5)\n",
    "\n",
    "print(out[\"answer\"])\n",
    "print(\"\\nValid citations:\", out[\"ok\"])\n",
    "print(\"\\nSources:\")\n",
    "print(\"\\n\".join(out[\"sources\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1760d",
   "metadata": {},
   "source": [
    "### Batch demo (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc85b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Q: What product does Apple describe as its first ‚Äúspatial computer,‚Äù and which operating system is it based on?\n",
      "OK: True\n",
      "A: Apple describes the Apple Vision Pro‚Ñ¢ as its first \"spatial computer,\" which is based on its visionOS‚Ñ¢ operating system [apple_2024_item_1_business].\n",
      "Sources: [apple_2024_item_1_business] (sec_10k_html) | [apple_2024_item_7_mda] (sec_10k_html) | [microsoft_2024_item_1_business] (sec_10k_html)\n",
      "\n",
      "================================================================================\n",
      "Q: In Apple‚Äôs ‚ÄúHome‚Äù product description, which device is described as a media streaming and gaming device, and which operating system is it based on?\n",
      "OK: True\n",
      "A: In Apple's \"Home\" product description, the device described as a media streaming and gaming device is Apple TV¬Æ, and it is based on the tvOS¬Æ operating system [apple_2024_item_1_business].\n",
      "Sources: [apple_2024_item_1_business] (sec_10k_html) | [apple_2024_item_7_mda] (sec_10k_html)\n",
      "\n",
      "================================================================================\n",
      "Q: As of September 28, 2024, which contractual obligation had the largest amount payable within 12 months, and what was that amount?\n",
      "OK: True\n",
      "A: As of September 28, 2024, the contractual obligation with the largest amount payable within 12 months was the Company's outstanding fixed-rate notes (debt), with $10.9 billion payable within 12 months. This is larger than the $10.0 billion of commercial paper payable within 12 months and the $2.0 billion of fixed lease payment obligations payable within 12 months [apple_2024_item_7_mda].\n",
      "Sources: [apple_2024_item_7_mda] (sec_10k_html) | [microsoft_2024_item_7_mda] (sec_10k_html)\n"
     ]
    }
   ],
   "source": [
    "demo_queries = [\n",
    "    \"What product does Apple describe as its first ‚Äúspatial computer,‚Äù and which operating system is it based on?\",\n",
    "    \"In Apple‚Äôs ‚ÄúHome‚Äù product description, which device is described as a media streaming and gaming device, and which operating system is it based on?\",\n",
    "    \"As of September 28, 2024, which contractual obligation had the largest amount payable within 12 months, and what was that amount?\",\n",
    "]\n",
    "\n",
    "for q in demo_queries:\n",
    "    out = run_query(q, use_rerank=False, k=5)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"OK:\", out[\"ok\"])\n",
    "    print(\"A:\", out[\"answer\"])\n",
    "    print(\"Sources:\", \" | \".join(out[\"sources\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc494769",
   "metadata": {},
   "source": [
    "## Vector vs Rerank comparison\n",
    "\n",
    "This section runs the same query twice:\n",
    "\n",
    "- **Vector baseline** (`use_rerank=False`)\n",
    "- **LLM rerank** (`use_rerank=True`)\n",
    "\n",
    "It then compares:\n",
    "- retrieved top-k (rank / score / doc_id / title)\n",
    "- answer + citation validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "920be1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helpers for demo output (orchestration-only) ---\n",
    "def preview_retrieved(retrieved, max_rows=5):\n",
    "    rows = []\n",
    "    for r in (retrieved or [])[:max_rows]:\n",
    "        rows.append({\n",
    "            \"rank\": r.get(\"rank\"),\n",
    "            \"score\": r.get(\"score\"),\n",
    "            \"doc_id\": r.get(\"doc_id\"),\n",
    "            \"title\": (r.get(\"title\") or \"\")[:90],\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def compare_top1(vec_retrieved, rr_retrieved):\n",
    "    v1 = (vec_retrieved or [{}])[0].get(\"doc_id\")\n",
    "    r1 = (rr_retrieved  or [{}])[0].get(\"doc_id\")\n",
    "    return {\"vector_top1\": v1, \"rerank_top1\": r1, \"changed\": (v1 != r1)}\n",
    "\n",
    "def preview_context_snippets(retrieved, k=3, max_chars=280):\n",
    "    \"\"\"Minimal 'eyes-on' context check: show a small snippet of top chunks.\"\"\"\n",
    "    for r in (retrieved or [])[:k]:\n",
    "        print(\"-\" * 90)\n",
    "        print(f\"[rank={r.get('rank')}] score={r.get('score'):.4f}\")\n",
    "        print(f\"{r.get('doc_id')} | {r.get('section')}\")\n",
    "        text = (r.get(\"content\") or \"\")\n",
    "        print(text[:max_chars].replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63da5208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Which product is described as the company‚Äôs first spatial computer, and what operating system is it based on?\n",
      "\n",
      "=== Retrieval top-5 (vector) [metadata preview] ===\n",
      "[{'rank': 1, 'score': 0.4421590566635132, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}, {'rank': 2, 'score': 0.4192088842391968, 'doc_id': 'amd_2024_item_1_business', 'title': ''}, {'rank': 3, 'score': 0.41882139444351196, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}, {'rank': 4, 'score': 0.4184524714946747, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}, {'rank': 5, 'score': 0.40680205821990967, 'doc_id': 'amd_2024_item_1_business', 'title': ''}]\n",
      "\n",
      "=== Retrieval top-5 (rerank) [metadata preview] ===\n",
      "[{'rank': 1, 'score': 0.39269906282424927, 'doc_id': 'apple_2024_item_1_business', 'title': ''}, {'rank': 2, 'score': 0.4421590566635132, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}, {'rank': 3, 'score': 0.4192088842391968, 'doc_id': 'amd_2024_item_1_business', 'title': ''}, {'rank': 4, 'score': 0.41882139444351196, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}, {'rank': 5, 'score': 0.4184524714946747, 'doc_id': 'microsoft_2024_item_1_business', 'title': ''}]\n",
      "\n",
      "=== Top-1 change ===\n",
      "{'vector_top1': 'microsoft_2024_item_1_business', 'rerank_top1': 'apple_2024_item_1_business', 'changed': True}\n",
      "\n",
      "=== Context snippets (vector top-3) ===\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=1] score=0.4422\n",
      "microsoft_2024_item_1_business | Item 1 - Business\n",
      "Item 1 Note About Forward-Looking Statements This report includes estimates, projections, statements relating to our business plans, objectives, and expected operating results that are ‚Äúforward-looking statements‚Äù within the meaning of the Private Securities Litigation Reform Act\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=2] score=0.4192\n",
      "amd_2024_item_1_business | Item 1 - Business\n",
      "ITEM 1. BUSINESS Cautionary Statement Regarding Forward-Looking Statements The statements in this report include forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. These forward-looking statements are based on current expectatio\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=3] score=0.4188\n",
      "microsoft_2024_item_1_business | Item 1 - Business\n",
      "Item 1 Note About Forward-Looking Statements This report includes estimates, projections, statements relating to our business plans, objectives, and expected operating results that are ‚Äúforward-looking statements‚Äù within the meaning of the Private Securities Litigation Reform Act\n",
      "\n",
      "=== Context snippets (rerank top-3) ===\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=1] score=0.3927\n",
      "apple_2024_item_1_business | Item 1 - Business\n",
      "Item 1. Business Company Background The Company designs, manufactures and markets smartphones, personal computers, tablets, wearables and accessories, and sells a variety of related services. The Company‚Äôs fiscal year is the 52- or 53-week period that ends on the last Saturday of\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=2] score=0.4422\n",
      "microsoft_2024_item_1_business | Item 1 - Business\n",
      "Item 1 Note About Forward-Looking Statements This report includes estimates, projections, statements relating to our business plans, objectives, and expected operating results that are ‚Äúforward-looking statements‚Äù within the meaning of the Private Securities Litigation Reform Act\n",
      "------------------------------------------------------------------------------------------\n",
      "[rank=3] score=0.4192\n",
      "amd_2024_item_1_business | Item 1 - Business\n",
      "ITEM 1. BUSINESS Cautionary Statement Regarding Forward-Looking Statements The statements in this report include forward-looking statements within the meaning of the Private Securities Litigation Reform Act of 1995. These forward-looking statements are based on current expectatio\n",
      "\n",
      "=== Answer (vector) ===\n",
      "The provided context does not contain information about a product described as the company‚Äôs first spatial computer or the operating system it is based on. Therefore, I don't have enough information to answer this question.\n",
      "Citations OK: True\n",
      "Sources:\n",
      "[microsoft_2024_item_1_business] (sec_10k_html)\n",
      "[amd_2024_item_1_business] (sec_10k_html)\n",
      "\n",
      "=== Answer (rerank) ===\n",
      "The product described as the company‚Äôs first spatial computer is Apple Vision Pro‚Ñ¢, and it is based on the visionOS‚Ñ¢ operating system [apple_2024_item_1_business].\n",
      "Citations OK: True\n",
      "Sources:\n",
      "[apple_2024_item_1_business] (sec_10k_html)\n",
      "[microsoft_2024_item_1_business] (sec_10k_html)\n",
      "[amd_2024_item_1_business] (sec_10k_html)\n"
     ]
    }
   ],
   "source": [
    "# --- run comparison ---\n",
    "QUERY = \"Which product is described as the company‚Äôs first spatial computer, and what operating system is it based on?\"\n",
    "\n",
    "out_vec = run_query(QUERY, use_rerank=False, k=5)\n",
    "out_rr  = run_query(QUERY, use_rerank=True,  k=5)\n",
    "\n",
    "print(\"QUERY:\", QUERY)\n",
    "\n",
    "# (A) Compact table-like preview (metadata)\n",
    "print(\"\\n=== Retrieval top-5 (vector) [metadata preview] ===\")\n",
    "print(preview_retrieved(out_vec.get(\"retrieved\", []), max_rows=5))\n",
    "\n",
    "print(\"\\n=== Retrieval top-5 (rerank) [metadata preview] ===\")\n",
    "print(preview_retrieved(out_rr.get(\"retrieved\", []), max_rows=5))\n",
    "\n",
    "print(\"\\n=== Top-1 change ===\")\n",
    "print(compare_top1(out_vec.get(\"retrieved\", []), out_rr.get(\"retrieved\", [])))\n",
    "\n",
    "# (B) Eyes-on context quality check (content snippets)\n",
    "print(\"\\n=== Context snippets (vector top-3) ===\")\n",
    "preview_context_snippets(out_vec.get(\"retrieved\", []), k=3, max_chars=280)\n",
    "\n",
    "print(\"\\n=== Context snippets (rerank top-3) ===\")\n",
    "preview_context_snippets(out_rr.get(\"retrieved\", []), k=3, max_chars=280)\n",
    "\n",
    "# (C) Answers + citations\n",
    "print(\"\\n=== Answer (vector) ===\")\n",
    "print(out_vec.get(\"answer\", \"\"))\n",
    "print(\"Citations OK:\", out_vec.get(\"ok\"))\n",
    "print(\"Sources:\")\n",
    "print(\"\\n\".join(out_vec.get(\"sources\", [])))\n",
    "\n",
    "print(\"\\n=== Answer (rerank) ===\")\n",
    "print(out_rr.get(\"answer\", \"\"))\n",
    "print(\"Citations OK:\", out_rr.get(\"ok\"))\n",
    "print(\"Sources:\")\n",
    "print(\"\\n\".join(out_rr.get(\"sources\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e79e3",
   "metadata": {},
   "source": [
    "### üîé Result Analysis: Vector vs LLM Rerank\n",
    "\n",
    "For this query, the company name was intentionally omitted to introduce cross-company ambiguity.\n",
    "\n",
    "#### Vector Baseline\n",
    "\n",
    "- Top-1 retrieved document: `microsoft_2024_item_1_business`\n",
    "- Apple business section was not ranked at the top.\n",
    "- Generated answer correctly abstained due to insufficient grounded context.\n",
    "\n",
    "This indicates that the vector retriever struggled with generic phrasing such as \"product\" and \"operating system,\" which appear across multiple companies.\n",
    "\n",
    "---\n",
    "\n",
    "#### LLM Rerank\n",
    "\n",
    "- Top-1 document changed to: `apple_2024_item_1_business`\n",
    "- Ranking corrected from Microsoft ‚Üí Apple.\n",
    "- Generated answer correctly identified:\n",
    "  - **Product:** Apple Vision Pro‚Ñ¢\n",
    "  - **Operating System:** visionOS‚Ñ¢\n",
    "\n",
    "The reranker successfully re-ordered the candidate documents based on deeper semantic understanding, enabling correct answer generation.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Key Takeaway\n",
    "\n",
    "- The correct document was already present in the candidate pool.\n",
    "- The performance difference came purely from ranking correction.\n",
    "- This demonstrates the value of LLM-based reranking for ambiguous, cross-company queries.\n",
    "- No hallucination occurred in either setting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM4D9TnIG97GvTZ0Cg2ueGT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (invest-rag)",
   "language": "python",
   "name": "invest-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
